{
  "evalId": "eval-fNi-2025-11-21T11:02:07",
  "results": {
    "version": 3,
    "timestamp": "2025-11-21T11:02:07.678Z",
    "prompts": [
      {
        "raw": "agent-matcher-v1",
        "label": "Current LLM Prompt (Hook Line 234-241)",
        "id": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "provider": "anthropic:claude-3-5-haiku-20241022",
        "metrics": {
          "score": 6.25,
          "testPassCount": 0,
          "testFailCount": 53,
          "testErrorCount": 0,
          "assertPassCount": 25,
          "assertFailCount": 187,
          "totalLatencyMs": 32643,
          "tokenUsage": {
            "prompt": 130,
            "completion": 1000,
            "cached": 4859,
            "total": 5989,
            "numRequests": 53,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 0,
              "prompt": 0,
              "completion": 0,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.021751199999999974
        }
      }
    ],
    "results": [
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "b3160607-788e-4aa2-b69c-c0f64ea8aa72",
        "latencyMs": 3159,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "total": 113,
            "prompt": 13,
            "completion": 100
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "PostgreSQL query optimization - clear database request",
          "vars": {
            "user_request": "optimize this PostgreSQL query"
          },
          "metadata": {
            "category": "clear-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "postgres-pro"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 0,
        "vars": {
          "user_request": "optimize this PostgreSQL query"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested"
            }
          ]
        },
        "id": "972d578b-d404-46d0-8473-1145d0a7231b",
        "latencyMs": 3206,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "total": 113,
            "prompt": 13,
            "completion": 100
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Event sourcing aggregate design",
          "vars": {
            "user_request": "help me design an aggregate for my event sourcing system"
          },
          "metadata": {
            "category": "clear-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "eventsourcing-expert"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 1,
        "vars": {
          "user_request": "help me design an aggregate for my event sourcing system"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested"
            }
          ]
        },
        "id": "1b2015c0-598b-4f5f-9bed-51f186759ac3",
        "latencyMs": 3044,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "total": 113,
            "prompt": 13,
            "completion": 100
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Datadog APM tracing setup",
          "vars": {
            "user_request": "set up Datadog APM tracing in my Python app"
          },
          "metadata": {
            "category": "clear-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "datadog-specialist"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 2,
        "vars": {
          "user_request": "set up Datadog APM tracing in my Python app"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent test-automator should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent test-automator should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for finding and pairing appropriate agents\n- Could be used in various contexts like customer service, sales, support, or multi-agent systems\n- Potentially matches agents based on specific criteria or compatibility\n\n2."
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent test-automator should trigger but was not suggested"
            }
          ]
        },
        "id": "85741e65-e0e2-4654-9dc3-4afd72e30739",
        "latencyMs": 3254,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for finding and pairing appropriate agents\n- Could be used in various contexts like customer service, sales, support, or multi-agent systems\n- Potentially matches agents based on specific criteria or compatibility\n\n2.",
          "tokenUsage": {
            "total": 113,
            "prompt": 13,
            "completion": 100
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Test automation framework setup",
          "vars": {
            "user_request": "help me set up automated testing for my application"
          },
          "metadata": {
            "category": "clear-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "test-automator"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 3,
        "vars": {
          "user_request": "help me set up automated testing for my application"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "d2874a41-ed71-4566-ba3b-a1f032307989",
        "latencyMs": 3305,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "total": 113,
            "prompt": 13,
            "completion": 100
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "API endpoint design",
          "vars": {
            "user_request": "design RESTful API endpoints for user management"
          },
          "metadata": {
            "category": "clear-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "api-designer"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 4,
        "vars": {
          "user_request": "design RESTful API endpoints for user management"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "22790763-5b12-463b-bcf7-effa93e8aa2f",
        "latencyMs": 3474,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "total": 113,
            "prompt": 13,
            "completion": 100
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Kubernetes deployment configuration",
          "vars": {
            "user_request": "create Kubernetes manifests for my microservice"
          },
          "metadata": {
            "category": "clear-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "kubernetes-specialist"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 5,
        "vars": {
          "user_request": "create Kubernetes manifests for my microservice"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "6e144c9b-c25b-4a95-9895-68633e793019",
        "latencyMs": 3004,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "total": 113,
            "prompt": 13,
            "completion": 100
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Python Django application development",
          "vars": {
            "user_request": "build a Django REST API with authentication"
          },
          "metadata": {
            "category": "clear-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "django-developer",
            "python-pro"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 6,
        "vars": {
          "user_request": "build a Django REST API with authentication"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "02483075-8f23-4eee-be02-6e54111eeafc",
        "latencyMs": 3067,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "total": 113,
            "prompt": 13,
            "completion": 100
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Security vulnerability assessment",
          "vars": {
            "user_request": "audit my application for security vulnerabilities"
          },
          "metadata": {
            "category": "clear-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "qa-expert"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 7,
        "vars": {
          "user_request": "audit my application for security vulnerabilities"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "c0bb05ec-ff16-401c-9f31-6f10f424f666",
        "latencyMs": 3127,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "total": 113,
            "prompt": 13,
            "completion": 100
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Performance optimization request",
          "vars": {
            "user_request": "my API is slow, help me optimize performance"
          },
          "metadata": {
            "category": "clear-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "backend-developer"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 8,
        "vars": {
          "user_request": "my API is slow, help me optimize performance"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent research-analyst should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent research-analyst should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Let me break down some potential key aspects and functionalities:\n\n1. Purpose:\n- Likely used for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Matching Criteria:"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent research-analyst should trigger but was not suggested"
            }
          ]
        },
        "id": "895b10d8-efd6-4416-98af-ffeff251fabf",
        "latencyMs": 3356,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Let me break down some potential key aspects and functionalities:\n\n1. Purpose:\n- Likely used for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Matching Criteria:",
          "tokenUsage": {
            "total": 113,
            "prompt": 13,
            "completion": 100
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Documentation research request",
          "vars": {
            "user_request": "look up documentation for FastAPI async patterns"
          },
          "metadata": {
            "category": "clear-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "research-analyst"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 9,
        "vars": {
          "user_request": "look up documentation for FastAPI async patterns"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "c5f1741d-cebf-4c63-a1cd-d448679ebe8a",
        "latencyMs": 7,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Ambiguous fix request",
          "vars": {
            "user_request": "fix this"
          },
          "metadata": {
            "category": "ambiguous-short",
            "expected_strategy": "llm"
          },
          "expected_agents": [
            "NONE"
          ],
          "priority": "NONE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 10,
        "vars": {
          "user_request": "fix this"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "0eea3d5a-1311-453d-86a8-26c634b8e81f",
        "latencyMs": 3,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Vague improvement request",
          "vars": {
            "user_request": "make it better"
          },
          "metadata": {
            "category": "ambiguous-short",
            "expected_strategy": "llm"
          },
          "expected_agents": [
            "NONE"
          ],
          "priority": "NONE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 11,
        "vars": {
          "user_request": "make it better"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "bd2c1bf4-1ce2-4e99-ad6e-8b0614264268",
        "latencyMs": 0,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Generic help request",
          "vars": {
            "user_request": "help"
          },
          "metadata": {
            "category": "ambiguous-short",
            "expected_strategy": "llm"
          },
          "expected_agents": [
            "NONE"
          ],
          "priority": "NONE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 12,
        "vars": {
          "user_request": "help"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "ded4119e-eb30-468a-8d0a-31c912a23087",
        "latencyMs": 2,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Vague check request",
          "vars": {
            "user_request": "check this code"
          },
          "metadata": {
            "category": "ambiguous-short",
            "expected_strategy": "llm"
          },
          "expected_agents": [
            "code-reviewer"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 13,
        "vars": {
          "user_request": "check this code"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "96d35452-c702-49e2-b13d-8dc0e3e36674",
        "latencyMs": 6,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Generic review request",
          "vars": {
            "user_request": "review my work"
          },
          "metadata": {
            "category": "ambiguous-short",
            "expected_strategy": "llm"
          },
          "expected_agents": [
            "code-reviewer"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 14,
        "vars": {
          "user_request": "review my work"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "60bdeb49-9aa3-4ac4-bb74-a50b8432411a",
        "latencyMs": 6,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Ambiguous analyze request",
          "vars": {
            "user_request": "analyze this"
          },
          "metadata": {
            "category": "ambiguous-short",
            "expected_strategy": "llm"
          },
          "expected_agents": [
            "NONE"
          ],
          "priority": "NONE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 15,
        "vars": {
          "user_request": "analyze this"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent research-analyst should trigger but was not suggested; PROACTIVE agent test-automator should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent research-analyst should trigger but was not suggested; PROACTIVE agent test-automator should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent research-analyst should trigger but was not suggested; PROACTIVE agent test-automator should trigger but was not suggested"
            }
          ]
        },
        "id": "60041db3-6e8e-4549-b45e-63d93e6b9b67",
        "latencyMs": 4,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Full stack implementation with testing",
          "vars": {
            "user_request": "implement user registration API with tests and documentation"
          },
          "metadata": {
            "category": "multi-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "backend-developer",
            "test-automator",
            "documentation-engineer"
          ],
          "priority": "MULTIPLE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 16,
        "vars": {
          "user_request": "implement user registration API with tests and documentation"
        },
        "metadata": {
          "category": "multi-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested"
            }
          ]
        },
        "id": "1191a9d2-b2f4-4a8d-be1f-daf44bf008f2",
        "latencyMs": 5,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Database schema with event sourcing",
          "vars": {
            "user_request": "design PostgreSQL schema for event sourced aggregates"
          },
          "metadata": {
            "category": "multi-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "postgres-pro",
            "eventsourcing-expert"
          ],
          "priority": "MULTIPLE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 17,
        "vars": {
          "user_request": "design PostgreSQL schema for event sourced aggregates"
        },
        "metadata": {
          "category": "multi-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested"
            }
          ]
        },
        "id": "e5375690-d51e-466f-8335-c7045a49bc1f",
        "latencyMs": 6,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Kubernetes deployment with monitoring",
          "vars": {
            "user_request": "deploy to Kubernetes with Datadog monitoring"
          },
          "metadata": {
            "category": "multi-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "kubernetes-specialist",
            "datadog-specialist"
          ],
          "priority": "MULTIPLE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 18,
        "vars": {
          "user_request": "deploy to Kubernetes with Datadog monitoring"
        },
        "metadata": {
          "category": "multi-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent test-automator should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent test-automator should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent test-automator should trigger but was not suggested"
            }
          ]
        },
        "id": "da5b8bb0-6d70-4ac4-b395-1211d0ce0c53",
        "latencyMs": 6,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "API development with security testing",
          "vars": {
            "user_request": "build REST API with security audit and tests"
          },
          "metadata": {
            "category": "multi-domain",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "api-designer",
            "qa-expert",
            "test-automator"
          ],
          "priority": "MULTIPLE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 19,
        "vars": {
          "user_request": "build REST API with security audit and tests"
        },
        "metadata": {
          "category": "multi-domain",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent research-analyst should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent research-analyst should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent research-analyst should trigger but was not suggested"
            }
          ]
        },
        "id": "4e860224-66e3-4f16-a303-545806add17c",
        "latencyMs": 7,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "How does framework work",
          "vars": {
            "user_request": "how does Django's ORM handle database transactions?"
          },
          "metadata": {
            "category": "proactive-research",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "research-analyst"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 20,
        "vars": {
          "user_request": "how does Django's ORM handle database transactions?"
        },
        "metadata": {
          "category": "proactive-research",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent research-analyst should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent research-analyst should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent research-analyst should trigger but was not suggested"
            }
          ]
        },
        "id": "45c38530-6321-4af7-98c6-e8c87076ae8a",
        "latencyMs": 7,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Best practices inquiry",
          "vars": {
            "user_request": "what are best practices for PostgreSQL connection pooling?"
          },
          "metadata": {
            "category": "proactive-research",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "research-analyst"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 21,
        "vars": {
          "user_request": "what are best practices for PostgreSQL connection pooling?"
        },
        "metadata": {
          "category": "proactive-research",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested; PROACTIVE agent research-analyst should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested; PROACTIVE agent research-analyst should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested; PROACTIVE agent research-analyst should trigger but was not suggested"
            }
          ]
        },
        "id": "b823ee82-b056-4471-b17e-3ceb2bf619f0",
        "latencyMs": 10,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Documentation lookup",
          "vars": {
            "user_request": "fetch documentation for OpenTelemetry Python SDK"
          },
          "metadata": {
            "category": "proactive-research",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "research-analyst"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 22,
        "vars": {
          "user_request": "fetch documentation for OpenTelemetry Python SDK"
        },
        "metadata": {
          "category": "proactive-research",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent research-analyst should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent research-analyst should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent research-analyst should trigger but was not suggested"
            }
          ]
        },
        "id": "7525ab4d-5486-4ace-be3f-b8896e6cde4a",
        "latencyMs": 9,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Library research",
          "vars": {
            "user_request": "research ddtrace library features"
          },
          "metadata": {
            "category": "proactive-research",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "research-analyst"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 23,
        "vars": {
          "user_request": "research ddtrace library features"
        },
        "metadata": {
          "category": "proactive-research",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested; PROACTIVE agent research-analyst should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested; PROACTIVE agent research-analyst should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested; PROACTIVE agent research-analyst should trigger but was not suggested"
            }
          ]
        },
        "id": "36a9bf1e-9e7f-4389-857c-74cb49e54eed",
        "latencyMs": 9,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "API reference lookup",
          "vars": {
            "user_request": "find API reference for Datadog metrics submission"
          },
          "metadata": {
            "category": "proactive-research",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "research-analyst"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 24,
        "vars": {
          "user_request": "find API reference for Datadog metrics submission"
        },
        "metadata": {
          "category": "proactive-research",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested"
            }
          ]
        },
        "id": "0c5150df-53be-4c6f-a77c-493cfab44c37",
        "latencyMs": 4,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Synonym for monitoring - observability",
          "vars": {
            "user_request": "implement observability for my microservices"
          },
          "metadata": {
            "category": "edge-case-synonym",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "datadog-specialist"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 25,
        "vars": {
          "user_request": "implement observability for my microservices"
        },
        "metadata": {
          "category": "edge-case-synonym",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested"
            }
          ]
        },
        "id": "6db9fe5c-ae39-4fb3-8b8d-81e87a866f61",
        "latencyMs": 6,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Synonym for monitoring - instrumentation",
          "vars": {
            "user_request": "add instrumentation to track request latency"
          },
          "metadata": {
            "category": "edge-case-synonym",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "datadog-specialist"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 26,
        "vars": {
          "user_request": "add instrumentation to track request latency"
        },
        "metadata": {
          "category": "edge-case-synonym",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent test-automator should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent test-automator should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent test-automator should trigger but was not suggested"
            }
          ]
        },
        "id": "d6dcd45f-0973-4641-aba3-5983c1ec89a7",
        "latencyMs": 7,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Synonym for testing - QA",
          "vars": {
            "user_request": "run quality assurance checks"
          },
          "metadata": {
            "category": "edge-case-synonym",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "test-automator",
            "qa-expert"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 27,
        "vars": {
          "user_request": "run quality assurance checks"
        },
        "metadata": {
          "category": "edge-case-synonym",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "68a45efa-d5ef-4374-b8ef-4748d912c3a3",
        "latencyMs": 7,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Indirect reference - query performance",
          "vars": {
            "user_request": "my database queries are taking too long"
          },
          "metadata": {
            "category": "edge-case-indirect",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "postgres-pro"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 28,
        "vars": {
          "user_request": "my database queries are taking too long"
        },
        "metadata": {
          "category": "edge-case-indirect",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "040fbd67-4ad6-492f-bd35-5f4d4059eea3",
        "latencyMs": 8,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Indirect reference - distributed tracing",
          "vars": {
            "user_request": "trace requests across my microservices"
          },
          "metadata": {
            "category": "edge-case-indirect",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "datadog-specialist"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 29,
        "vars": {
          "user_request": "trace requests across my microservices"
        },
        "metadata": {
          "category": "edge-case-indirect",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "77073b38-1917-431f-b009-3d6d4d589088",
        "latencyMs": 14,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Indirect reference - container orchestration",
          "vars": {
            "user_request": "manage my containerized applications at scale"
          },
          "metadata": {
            "category": "edge-case-indirect",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "kubernetes-specialist"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 30,
        "vars": {
          "user_request": "manage my containerized applications at scale"
        },
        "metadata": {
          "category": "edge-case-indirect",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "726bc9e1-f228-4f01-bb37-74b101bcfeb2",
        "latencyMs": 14,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Typo - postgres vs postgresql",
          "vars": {
            "user_request": "optimize postgres database indexes"
          },
          "metadata": {
            "category": "typo",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "postgres-pro"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 31,
        "vars": {
          "user_request": "optimize postgres database indexes"
        },
        "metadata": {
          "category": "typo",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "bc12254f-402a-4a33-ad8d-3a6dc3ba9541",
        "latencyMs": 13,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Typo - k8s abbreviation",
          "vars": {
            "user_request": "deploy to k8s cluster"
          },
          "metadata": {
            "category": "typo",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "kubernetes-specialist"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 32,
        "vars": {
          "user_request": "deploy to k8s cluster"
        },
        "metadata": {
          "category": "typo",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "162f21c8-67e0-4d97-a2e1-d0b84b591418",
        "latencyMs": 16,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Common abbreviation - API",
          "vars": {
            "user_request": "build REST API endpoints"
          },
          "metadata": {
            "category": "abbreviation",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "api-designer"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 33,
        "vars": {
          "user_request": "build REST API endpoints"
        },
        "metadata": {
          "category": "abbreviation",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested"
            }
          ]
        },
        "id": "44a8b4cf-1aba-48af-9022-6d4928ae5278",
        "latencyMs": 15,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Debug production issue with monitoring",
          "vars": {
            "user_request": "debug production error using Datadog traces"
          },
          "metadata": {
            "category": "complex-scenario",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "debugger",
            "datadog-specialist"
          ],
          "priority": "MULTIPLE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 34,
        "vars": {
          "user_request": "debug production error using Datadog traces"
        },
        "metadata": {
          "category": "complex-scenario",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent test-automator should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent test-automator should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent test-automator should trigger but was not suggested"
            }
          ]
        },
        "id": "548a183e-3e76-4d65-904e-fad2391d2bf4",
        "latencyMs": 13,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Migration with testing",
          "vars": {
            "user_request": "migrate database schema and ensure tests pass"
          },
          "metadata": {
            "category": "complex-scenario",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "postgres-pro",
            "test-automator"
          ],
          "priority": "MULTIPLE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 35,
        "vars": {
          "user_request": "migrate database schema and ensure tests pass"
        },
        "metadata": {
          "category": "complex-scenario",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested; PROACTIVE agent aws-cloud-specialist should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested; PROACTIVE agent aws-cloud-specialist should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested; PROACTIVE agent aws-cloud-specialist should trigger but was not suggested"
            }
          ]
        },
        "id": "db23cd53-38cd-4a92-adbe-c7ba0c301c7d",
        "latencyMs": 9,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Cloud infrastructure setup",
          "vars": {
            "user_request": "set up AWS infrastructure with monitoring and logging"
          },
          "metadata": {
            "category": "complex-scenario",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "aws-cloud-specialist",
            "datadog-specialist"
          ],
          "priority": "MULTIPLE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 36,
        "vars": {
          "user_request": "set up AWS infrastructure with monitoring and logging"
        },
        "metadata": {
          "category": "complex-scenario",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "e1995083-a49a-4683-ac93-427a203e860c",
        "latencyMs": 10,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Django-specific request",
          "vars": {
            "user_request": "create Django models for user authentication"
          },
          "metadata": {
            "category": "framework-specific",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "django-developer"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 37,
        "vars": {
          "user_request": "create Django models for user authentication"
        },
        "metadata": {
          "category": "framework-specific",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "e29231e9-a792-4888-9870-aa951094e999",
        "latencyMs": 10,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "FastAPI development",
          "vars": {
            "user_request": "build FastAPI application with async endpoints"
          },
          "metadata": {
            "category": "framework-specific",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "python-pro",
            "backend-developer"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 38,
        "vars": {
          "user_request": "build FastAPI application with async endpoints"
        },
        "metadata": {
          "category": "framework-specific",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "facb6953-7942-43b1-98ff-dfcd37d9a0ef",
        "latencyMs": 10,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Error debugging",
          "vars": {
            "user_request": "my application crashes on startup, help debug"
          },
          "metadata": {
            "category": "debugging",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "debugger"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 39,
        "vars": {
          "user_request": "my application crashes on startup, help debug"
        },
        "metadata": {
          "category": "debugging",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent test-automator should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent test-automator should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent test-automator should trigger but was not suggested"
            }
          ]
        },
        "id": "1dd3a634-35d5-4d67-89f9-815ae68ad159",
        "latencyMs": 7,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Test failure debugging",
          "vars": {
            "user_request": "tests are failing, help me fix them"
          },
          "metadata": {
            "category": "debugging",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "debugger",
            "test-automator"
          ],
          "priority": "MULTIPLE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 40,
        "vars": {
          "user_request": "tests are failing, help me fix them"
        },
        "metadata": {
          "category": "debugging",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "fb8c2164-ccb1-4bf0-80a8-6f9c7db1a1d3",
        "latencyMs": 12,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Performance bottleneck",
          "vars": {
            "user_request": "identify performance bottleneck in my API"
          },
          "metadata": {
            "category": "debugging",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "backend-developer"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 41,
        "vars": {
          "user_request": "identify performance bottleneck in my API"
        },
        "metadata": {
          "category": "debugging",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent test-automator should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent test-automator should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent test-automator should trigger but was not suggested"
            }
          ]
        },
        "id": "6e8b0221-1fa8-4228-8f40-12a6b11cb123",
        "latencyMs": 8,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Code review request",
          "vars": {
            "user_request": "review this pull request for quality"
          },
          "metadata": {
            "category": "code-review",
            "expected_strategy": "llm"
          },
          "expected_agents": [
            "code-reviewer"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 42,
        "vars": {
          "user_request": "review this pull request for quality"
        },
        "metadata": {
          "category": "code-review",
          "expected_strategy": "llm",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent research-analyst should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent research-analyst should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent research-analyst should trigger but was not suggested"
            }
          ]
        },
        "id": "26ef5123-9362-4436-887b-6b06af3d6278",
        "latencyMs": 14,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Documentation writing",
          "vars": {
            "user_request": "write API documentation for these endpoints"
          },
          "metadata": {
            "category": "documentation",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "documentation-engineer"
          ],
          "priority": "SHOULD",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 43,
        "vars": {
          "user_request": "write API documentation for these endpoints"
        },
        "metadata": {
          "category": "documentation",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested"
            }
          ]
        },
        "id": "ab401187-68de-4786-bffe-a50cbfad3e6c",
        "latencyMs": 21,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Metrics collection",
          "vars": {
            "user_request": "send custom metrics to Datadog"
          },
          "metadata": {
            "category": "metrics-telemetry",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "datadog-specialist"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 44,
        "vars": {
          "user_request": "send custom metrics to Datadog"
        },
        "metadata": {
          "category": "metrics-telemetry",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested"
            }
          ]
        },
        "id": "7724e21a-e8d8-4dea-8dad-a709309e38ce",
        "latencyMs": 35,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Log aggregation",
          "vars": {
            "user_request": "centralize logging with Datadog"
          },
          "metadata": {
            "category": "metrics-telemetry",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "datadog-specialist"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 45,
        "vars": {
          "user_request": "centralize logging with Datadog"
        },
        "metadata": {
          "category": "metrics-telemetry",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent datadog-specialist should trigger but was not suggested"
            }
          ]
        },
        "id": "1d531d51-089d-4cb2-b160-55c123a3b05b",
        "latencyMs": 38,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "OpenTelemetry setup",
          "vars": {
            "user_request": "instrument application with OpenTelemetry"
          },
          "metadata": {
            "category": "metrics-telemetry",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "datadog-specialist"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 46,
        "vars": {
          "user_request": "instrument application with OpenTelemetry"
        },
        "metadata": {
          "category": "metrics-telemetry",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested"
            }
          ]
        },
        "id": "65b68ca7-cf16-4dec-8b07-47ba4a07c5fe",
        "latencyMs": 40,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Projection implementation",
          "vars": {
            "user_request": "implement read model projections from event store"
          },
          "metadata": {
            "category": "event-sourcing",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "eventsourcing-expert"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 47,
        "vars": {
          "user_request": "implement read model projections from event store"
        },
        "metadata": {
          "category": "event-sourcing",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested"
            }
          ]
        },
        "id": "7cbce582-2778-426e-948d-797efd30b3d5",
        "latencyMs": 32,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "Domain events design",
          "vars": {
            "user_request": "design domain events for order aggregate"
          },
          "metadata": {
            "category": "event-sourcing",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "eventsourcing-expert"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 48,
        "vars": {
          "user_request": "design domain events for order aggregate"
        },
        "metadata": {
          "category": "event-sourcing",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested",
        "gradingResult": {
          "pass": false,
          "score": 0,
          "reason": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "PROACTIVE agent eventsourcing-expert should trigger but was not suggested"
            }
          ]
        },
        "id": "3f5c35c6-38a9-4773-b262-3559b7660232",
        "latencyMs": 16,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0,
        "success": false,
        "testCase": {
          "description": "CQRS pattern",
          "vars": {
            "user_request": "implement CQRS pattern for my application"
          },
          "metadata": {
            "category": "event-sourcing",
            "expected_strategy": "keyword"
          },
          "expected_agents": [
            "eventsourcing-expert"
          ],
          "priority": "MUST",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 49,
        "vars": {
          "user_request": "implement CQRS pattern for my application"
        },
        "metadata": {
          "category": "event-sourcing",
          "expected_strategy": "keyword",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "aff211b7-db0e-41fd-b38d-906da3ba29f6",
        "latencyMs": 12,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Completely unrelated request",
          "vars": {
            "user_request": "what's the weather today?"
          },
          "metadata": {
            "category": "no-match",
            "expected_strategy": "none"
          },
          "expected_agents": [
            "NONE"
          ],
          "priority": "NONE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 50,
        "vars": {
          "user_request": "what's the weather today?"
        },
        "metadata": {
          "category": "no-match",
          "expected_strategy": "none",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for finding and pairing appropriate agents\n- Could be used in various contexts like customer service, sales, support, or multi-agent systems\n- Potentially matches agents based on specific criteria or compatibility\n\n2."
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "caa402cb-f21a-46d1-8c08-80c43716dd9e",
        "latencyMs": 60,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for finding and pairing appropriate agents\n- Could be used in various contexts like customer service, sales, support, or multi-agent systems\n- Potentially matches agents based on specific criteria or compatibility\n\n2.",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "General conversation",
          "vars": {
            "user_request": "tell me a joke"
          },
          "metadata": {
            "category": "no-match",
            "expected_strategy": "none"
          },
          "expected_agents": [
            "NONE"
          ],
          "priority": "NONE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 51,
        "vars": {
          "user_request": "tell me a joke"
        },
        "metadata": {
          "category": "no-match",
          "expected_strategy": "none",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00041039999999999995,
        "error": "Should have returned NONE",
        "gradingResult": {
          "pass": false,
          "score": 0.25,
          "reason": "Should have returned NONE",
          "namedScores": {},
          "tokensUsed": {
            "total": 0,
            "prompt": 0,
            "completion": 0,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0,
              "reason": "Response contains invalid characters or extra text"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Invalid agent names: I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-"
            },
            {
              "pass": false,
              "score": 0,
              "reason": "Should have returned NONE"
            },
            {
              "pass": true,
              "score": 1,
              "reason": "PROACTIVE agents correctly handled"
            }
          ]
        },
        "id": "31c43494-179d-4337-bcc7-2eb97cc74979",
        "latencyMs": 109,
        "namedScores": {},
        "prompt": {
          "raw": "agent-matcher-v1",
          "label": "Current LLM Prompt (Hook Line 234-241)"
        },
        "promptId": "6b7eb3860ecf7b88edff74c09b90cae00fdf09bb30ecf86fb1870511afbd624b",
        "promptIdx": 0,
        "provider": {
          "id": "anthropic:claude-3-5-haiku-20241022",
          "label": ""
        },
        "response": {
          "output": "I'll help you understand the agent-matcher-v1 system. Based on the name, it sounds like a service or component designed to match agents or match-make between different agents. Here's a comprehensive overview:\n\n1. Purpose:\n- Likely a system for matching agents based on specific criteria\n- Could be used in various domains like customer service, sales, support, or multi-agent systems\n\n2. Potential Key Features:\n- Agent profile matching\n-",
          "tokenUsage": {
            "cached": 113,
            "total": 113
          },
          "finishReason": "length",
          "cost": 0.00041039999999999995
        },
        "score": 0.25,
        "success": false,
        "testCase": {
          "description": "Non-technical question",
          "vars": {
            "user_request": "what's the meaning of life?"
          },
          "metadata": {
            "category": "no-match",
            "expected_strategy": "none"
          },
          "expected_agents": [
            "NONE"
          ],
          "priority": "NONE",
          "assert": [
            {
              "type": "javascript",
              "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
            },
            {
              "type": "javascript",
              "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
            },
            {
              "type": "javascript",
              "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
            }
          ],
          "options": {}
        },
        "testIdx": 52,
        "vars": {
          "user_request": "what's the meaning of life?"
        },
        "metadata": {
          "category": "no-match",
          "expected_strategy": "none",
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      }
    ],
    "stats": {
      "successes": 0,
      "failures": 53,
      "errors": 0,
      "tokenUsage": {
        "prompt": 130,
        "completion": 1000,
        "cached": 4859,
        "total": 5989,
        "numRequests": 53,
        "completionDetails": {
          "reasoning": 0,
          "acceptedPrediction": 0,
          "rejectedPrediction": 0
        },
        "assertions": {
          "total": 0,
          "prompt": 0,
          "completion": 0,
          "cached": 0,
          "numRequests": 0,
          "completionDetails": {
            "reasoning": 0,
            "acceptedPrediction": 0,
            "rejectedPrediction": 0
          }
        }
      }
    }
  },
  "config": {
    "tags": {},
    "description": "Agent Discovery Hook - LLM Matching Evaluation",
    "prompts": [
      {
        "id": "agent-matcher-v1",
        "label": "Current LLM Prompt (Hook Line 234-241)",
        "prompt": "Analyze this request and suggest 1-5 most relevant agents.\n\nREQUEST: {{user_request}}\n\nAGENTS:\n- api-designer: Expert in RESTful API design, GraphQL, API documentation, versioning, and best practices for scalable API architectures\n- aws-cloud-specialist: PROACTIVE AWS cloud specialist - auto-engages for AWS services, CloudFormation, Lambda, ECS, RDS, S3, IAM, CloudWatch. Validates via Context7 MCP and WebFetch\n- backend-developer: Backend development specialist focused on server-side logic, API design, database integration, and scalable system architecture\n- claude-specialist: Expert in Claude AI API, Anthropic SDKs, prompt engineering, and AI integration best practices\n- code-reviewer: Systematic code review specialist analyzing code quality, best practices, security, performance, and maintainability\n- context-manager: Context window optimization specialist managing token usage, compaction strategies, and conversation efficiency\n- datadog-specialist: PROACTIVE Datadog and observability specialist - auto-engages for Datadog, OpenTelemetry, StatsD, DogStatsD, ddtrace, APM, distributed tracing, metrics collection, log aggregation, observability, monitoring. Validates via Context7 MCP and WebFetch\n- debugger: Debugging specialist skilled in troubleshooting, error analysis, diagnostic techniques, and systematic problem resolution\n- development-orchestrator: PROACTIVE orchestrator for complex multi-phase development workflows requiring 3+ specialized agents with sequential dependencies and quality gates\n- django-developer: Django development specialist with expertise in Django REST Framework, ORM, migrations, and Django best practices\n- documentation-engineer: Technical documentation specialist creating clear, comprehensive documentation including API docs, guides, and technical writing\n- eventsourcing-expert: Expert in Python eventsourcing library. Use proactively when working with event sourcing patterns, aggregates, domain events, event stores, projections, or when eventsourcing library is mentioned\n- github-installation-specialist: PROACTIVE GitHub Apps specialist - auto-engages for GitHub App development, installation authentication, GitHub API integration, webhook handling, and GitHub Apps best practices\n- kubernetes-specialist: Kubernetes specialist expert in container orchestration, deployments, services, scaling, and Kubernetes ecosystem tools\n- microservices-architect: Microservices architecture specialist designing distributed systems, service boundaries, inter-service communication, and resilience patterns\n- postgres-pro: Expert PostgreSQL specialist mastering database administration, performance optimization, and high availability\n- promptfoo-specialist: PROACTIVE promptfoo specialist for LLM testing, prompt evaluation, red teaming, and AI quality assurance\n- python-pro: Python development specialist with deep expertise in Python best practices, patterns, standard library, and ecosystem\n- qa-expert: Quality assurance specialist focused on testing strategies, quality metrics, and comprehensive QA processes\n- research-analyst: PROACTIVE research analyst - auto-engages for documentation lookups, library/framework research, best practices discovery, and comprehensive information gathering\n- task-distributor: Task orchestration specialist coordinating parallel execution of independent tasks across multiple specialized agents\n- test-automator: PROACTIVE test automation specialist - automatically engages when user mentions tests, testing, test automation, test frameworks, test coverage\n- toolkit-manager: PROACTIVE meta-agent for analyzing, improving, and managing the agent/skill toolkit itself\n- trend-analyst: Trend analysis and forecasting specialist identifying patterns, predicting trajectories, and providing strategic insights\n\nReturn ONLY comma-separated agent names (e.g., agent1,agent2) or NONE if unclear.\n"
      }
    ],
    "providers": [
      {
        "id": "anthropic:claude-3-5-haiku-20241022",
        "config": {
          "temperature": 0,
          "max_tokens": 100
        }
      }
    ],
    "tests": [
      {
        "description": "PostgreSQL query optimization - clear database request",
        "vars": {
          "user_request": "optimize this PostgreSQL query"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "postgres-pro"
        ],
        "priority": "MUST"
      },
      {
        "description": "Event sourcing aggregate design",
        "vars": {
          "user_request": "help me design an aggregate for my event sourcing system"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "eventsourcing-expert"
        ],
        "priority": "MUST"
      },
      {
        "description": "Datadog APM tracing setup",
        "vars": {
          "user_request": "set up Datadog APM tracing in my Python app"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "datadog-specialist"
        ],
        "priority": "MUST"
      },
      {
        "description": "Test automation framework setup",
        "vars": {
          "user_request": "help me set up automated testing for my application"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "test-automator"
        ],
        "priority": "MUST"
      },
      {
        "description": "API endpoint design",
        "vars": {
          "user_request": "design RESTful API endpoints for user management"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "api-designer"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Kubernetes deployment configuration",
        "vars": {
          "user_request": "create Kubernetes manifests for my microservice"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "kubernetes-specialist"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Python Django application development",
        "vars": {
          "user_request": "build a Django REST API with authentication"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "django-developer",
          "python-pro"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Security vulnerability assessment",
        "vars": {
          "user_request": "audit my application for security vulnerabilities"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "qa-expert"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Performance optimization request",
        "vars": {
          "user_request": "my API is slow, help me optimize performance"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "backend-developer"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Documentation research request",
        "vars": {
          "user_request": "look up documentation for FastAPI async patterns"
        },
        "metadata": {
          "category": "clear-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "research-analyst"
        ],
        "priority": "MUST"
      },
      {
        "description": "Ambiguous fix request",
        "vars": {
          "user_request": "fix this"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm"
        },
        "expected_agents": [
          "NONE"
        ],
        "priority": "NONE"
      },
      {
        "description": "Vague improvement request",
        "vars": {
          "user_request": "make it better"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm"
        },
        "expected_agents": [
          "NONE"
        ],
        "priority": "NONE"
      },
      {
        "description": "Generic help request",
        "vars": {
          "user_request": "help"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm"
        },
        "expected_agents": [
          "NONE"
        ],
        "priority": "NONE"
      },
      {
        "description": "Vague check request",
        "vars": {
          "user_request": "check this code"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm"
        },
        "expected_agents": [
          "code-reviewer"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Generic review request",
        "vars": {
          "user_request": "review my work"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm"
        },
        "expected_agents": [
          "code-reviewer"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Ambiguous analyze request",
        "vars": {
          "user_request": "analyze this"
        },
        "metadata": {
          "category": "ambiguous-short",
          "expected_strategy": "llm"
        },
        "expected_agents": [
          "NONE"
        ],
        "priority": "NONE"
      },
      {
        "description": "Full stack implementation with testing",
        "vars": {
          "user_request": "implement user registration API with tests and documentation"
        },
        "metadata": {
          "category": "multi-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "backend-developer",
          "test-automator",
          "documentation-engineer"
        ],
        "priority": "MULTIPLE"
      },
      {
        "description": "Database schema with event sourcing",
        "vars": {
          "user_request": "design PostgreSQL schema for event sourced aggregates"
        },
        "metadata": {
          "category": "multi-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "postgres-pro",
          "eventsourcing-expert"
        ],
        "priority": "MULTIPLE"
      },
      {
        "description": "Kubernetes deployment with monitoring",
        "vars": {
          "user_request": "deploy to Kubernetes with Datadog monitoring"
        },
        "metadata": {
          "category": "multi-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "kubernetes-specialist",
          "datadog-specialist"
        ],
        "priority": "MULTIPLE"
      },
      {
        "description": "API development with security testing",
        "vars": {
          "user_request": "build REST API with security audit and tests"
        },
        "metadata": {
          "category": "multi-domain",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "api-designer",
          "qa-expert",
          "test-automator"
        ],
        "priority": "MULTIPLE"
      },
      {
        "description": "How does framework work",
        "vars": {
          "user_request": "how does Django's ORM handle database transactions?"
        },
        "metadata": {
          "category": "proactive-research",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "research-analyst"
        ],
        "priority": "MUST"
      },
      {
        "description": "Best practices inquiry",
        "vars": {
          "user_request": "what are best practices for PostgreSQL connection pooling?"
        },
        "metadata": {
          "category": "proactive-research",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "research-analyst"
        ],
        "priority": "MUST"
      },
      {
        "description": "Documentation lookup",
        "vars": {
          "user_request": "fetch documentation for OpenTelemetry Python SDK"
        },
        "metadata": {
          "category": "proactive-research",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "research-analyst"
        ],
        "priority": "MUST"
      },
      {
        "description": "Library research",
        "vars": {
          "user_request": "research ddtrace library features"
        },
        "metadata": {
          "category": "proactive-research",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "research-analyst"
        ],
        "priority": "MUST"
      },
      {
        "description": "API reference lookup",
        "vars": {
          "user_request": "find API reference for Datadog metrics submission"
        },
        "metadata": {
          "category": "proactive-research",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "research-analyst"
        ],
        "priority": "MUST"
      },
      {
        "description": "Synonym for monitoring - observability",
        "vars": {
          "user_request": "implement observability for my microservices"
        },
        "metadata": {
          "category": "edge-case-synonym",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "datadog-specialist"
        ],
        "priority": "MUST"
      },
      {
        "description": "Synonym for monitoring - instrumentation",
        "vars": {
          "user_request": "add instrumentation to track request latency"
        },
        "metadata": {
          "category": "edge-case-synonym",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "datadog-specialist"
        ],
        "priority": "MUST"
      },
      {
        "description": "Synonym for testing - QA",
        "vars": {
          "user_request": "run quality assurance checks"
        },
        "metadata": {
          "category": "edge-case-synonym",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "test-automator",
          "qa-expert"
        ],
        "priority": "MUST"
      },
      {
        "description": "Indirect reference - query performance",
        "vars": {
          "user_request": "my database queries are taking too long"
        },
        "metadata": {
          "category": "edge-case-indirect",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "postgres-pro"
        ],
        "priority": "MUST"
      },
      {
        "description": "Indirect reference - distributed tracing",
        "vars": {
          "user_request": "trace requests across my microservices"
        },
        "metadata": {
          "category": "edge-case-indirect",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "datadog-specialist"
        ],
        "priority": "MUST"
      },
      {
        "description": "Indirect reference - container orchestration",
        "vars": {
          "user_request": "manage my containerized applications at scale"
        },
        "metadata": {
          "category": "edge-case-indirect",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "kubernetes-specialist"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Typo - postgres vs postgresql",
        "vars": {
          "user_request": "optimize postgres database indexes"
        },
        "metadata": {
          "category": "typo",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "postgres-pro"
        ],
        "priority": "MUST"
      },
      {
        "description": "Typo - k8s abbreviation",
        "vars": {
          "user_request": "deploy to k8s cluster"
        },
        "metadata": {
          "category": "typo",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "kubernetes-specialist"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Common abbreviation - API",
        "vars": {
          "user_request": "build REST API endpoints"
        },
        "metadata": {
          "category": "abbreviation",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "api-designer"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Debug production issue with monitoring",
        "vars": {
          "user_request": "debug production error using Datadog traces"
        },
        "metadata": {
          "category": "complex-scenario",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "debugger",
          "datadog-specialist"
        ],
        "priority": "MULTIPLE"
      },
      {
        "description": "Migration with testing",
        "vars": {
          "user_request": "migrate database schema and ensure tests pass"
        },
        "metadata": {
          "category": "complex-scenario",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "postgres-pro",
          "test-automator"
        ],
        "priority": "MULTIPLE"
      },
      {
        "description": "Cloud infrastructure setup",
        "vars": {
          "user_request": "set up AWS infrastructure with monitoring and logging"
        },
        "metadata": {
          "category": "complex-scenario",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "aws-cloud-specialist",
          "datadog-specialist"
        ],
        "priority": "MULTIPLE"
      },
      {
        "description": "Django-specific request",
        "vars": {
          "user_request": "create Django models for user authentication"
        },
        "metadata": {
          "category": "framework-specific",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "django-developer"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "FastAPI development",
        "vars": {
          "user_request": "build FastAPI application with async endpoints"
        },
        "metadata": {
          "category": "framework-specific",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "python-pro",
          "backend-developer"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Error debugging",
        "vars": {
          "user_request": "my application crashes on startup, help debug"
        },
        "metadata": {
          "category": "debugging",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "debugger"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Test failure debugging",
        "vars": {
          "user_request": "tests are failing, help me fix them"
        },
        "metadata": {
          "category": "debugging",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "debugger",
          "test-automator"
        ],
        "priority": "MULTIPLE"
      },
      {
        "description": "Performance bottleneck",
        "vars": {
          "user_request": "identify performance bottleneck in my API"
        },
        "metadata": {
          "category": "debugging",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "backend-developer"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Code review request",
        "vars": {
          "user_request": "review this pull request for quality"
        },
        "metadata": {
          "category": "code-review",
          "expected_strategy": "llm"
        },
        "expected_agents": [
          "code-reviewer"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Documentation writing",
        "vars": {
          "user_request": "write API documentation for these endpoints"
        },
        "metadata": {
          "category": "documentation",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "documentation-engineer"
        ],
        "priority": "SHOULD"
      },
      {
        "description": "Metrics collection",
        "vars": {
          "user_request": "send custom metrics to Datadog"
        },
        "metadata": {
          "category": "metrics-telemetry",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "datadog-specialist"
        ],
        "priority": "MUST"
      },
      {
        "description": "Log aggregation",
        "vars": {
          "user_request": "centralize logging with Datadog"
        },
        "metadata": {
          "category": "metrics-telemetry",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "datadog-specialist"
        ],
        "priority": "MUST"
      },
      {
        "description": "OpenTelemetry setup",
        "vars": {
          "user_request": "instrument application with OpenTelemetry"
        },
        "metadata": {
          "category": "metrics-telemetry",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "datadog-specialist"
        ],
        "priority": "MUST"
      },
      {
        "description": "Projection implementation",
        "vars": {
          "user_request": "implement read model projections from event store"
        },
        "metadata": {
          "category": "event-sourcing",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "eventsourcing-expert"
        ],
        "priority": "MUST"
      },
      {
        "description": "Domain events design",
        "vars": {
          "user_request": "design domain events for order aggregate"
        },
        "metadata": {
          "category": "event-sourcing",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "eventsourcing-expert"
        ],
        "priority": "MUST"
      },
      {
        "description": "CQRS pattern",
        "vars": {
          "user_request": "implement CQRS pattern for my application"
        },
        "metadata": {
          "category": "event-sourcing",
          "expected_strategy": "keyword"
        },
        "expected_agents": [
          "eventsourcing-expert"
        ],
        "priority": "MUST"
      },
      {
        "description": "Completely unrelated request",
        "vars": {
          "user_request": "what's the weather today?"
        },
        "metadata": {
          "category": "no-match",
          "expected_strategy": "none"
        },
        "expected_agents": [
          "NONE"
        ],
        "priority": "NONE"
      },
      {
        "description": "General conversation",
        "vars": {
          "user_request": "tell me a joke"
        },
        "metadata": {
          "category": "no-match",
          "expected_strategy": "none"
        },
        "expected_agents": [
          "NONE"
        ],
        "priority": "NONE"
      },
      {
        "description": "Non-technical question",
        "vars": {
          "user_request": "what's the meaning of life?"
        },
        "metadata": {
          "category": "no-match",
          "expected_strategy": "none"
        },
        "expected_agents": [
          "NONE"
        ],
        "priority": "NONE"
      }
    ],
    "scenarios": [],
    "env": {},
    "sharing": false,
    "defaultTest": {
      "assert": [
        {
          "type": "javascript",
          "value": "// Response should be agent names or NONE\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\n// Check format: comma-separated names, no extra text\nconst hasExtraText = /[^a-z0-9,\\-_\\s]/i.test(trimmed);\nif (hasExtraText) {\n  return {\n    pass: false,\n    score: 0,\n    reason: 'Response contains invalid characters or extra text'\n  };\n}\n\nconst agents = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst validCount = agents.length >= 1 && agents.length <= 5;\n\nreturn {\n  pass: validCount,\n  score: validCount ? 1 : 0,\n  reason: validCount ? 'Valid format' : `Invalid agent count: ${agents.length}`\n};\n"
        },
        {
          "type": "javascript",
          "value": "const validAgents = [\n  'api-designer', 'aws-cloud-specialist', 'backend-developer', 'claude-specialist',\n  'code-reviewer', 'context-manager', 'datadog-specialist', 'debugger',\n  'development-orchestrator', 'django-developer', 'documentation-engineer',\n  'eventsourcing-expert', 'github-installation-specialist', 'kubernetes-specialist',\n  'microservices-architect', 'postgres-pro', 'promptfoo-specialist', 'python-pro',\n  'qa-expert', 'research-analyst', 'task-distributor', 'test-automator',\n  'toolkit-manager', 'trend-analyst'\n];\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') return { pass: true, score: 1 };\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\nconst invalid = suggested.filter(a => !validAgents.includes(a));\n\nif (invalid.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Invalid agent names: ${invalid.join(', ')}`\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'All agent names are valid' };\n"
        },
        {
          "type": "javascript",
          "value": "// Get expected agents from test metadata\nconst expected = context.vars.expected_agents || [];\nif (expected.length === 0 || expected[0] === 'NONE') {\n  // For NONE expectations, check that output is NONE\n  const trimmed = output.trim();\n  return {\n    pass: trimmed === 'NONE' || trimmed === '',\n    score: (trimmed === 'NONE' || trimmed === '') ? 1 : 0,\n    reason: trimmed === 'NONE' ? 'Correctly returned NONE' : 'Should have returned NONE'\n  };\n}\n\nconst trimmed = output.trim();\nif (trimmed === 'NONE') {\n  return {\n    pass: false,\n    score: 0,\n    reason: `Expected agents ${expected.join(', ')} but got NONE`\n  };\n}\n\nconst suggested = trimmed.split(',').map(a => a.trim()).filter(a => a);\n\n// Calculate precision, recall, F1\nconst expectedSet = new Set(expected);\nconst suggestedSet = new Set(suggested);\n\nconst truePositives = suggested.filter(a => expectedSet.has(a)).length;\nconst falsePositives = suggested.filter(a => !expectedSet.has(a)).length;\nconst falseNegatives = expected.filter(a => !suggestedSet.has(a)).length;\n\nconst precision = truePositives / (truePositives + falsePositives) || 0;\nconst recall = truePositives / (truePositives + falseNegatives) || 0;\nconst f1 = precision + recall > 0 ? (2 * precision * recall) / (precision + recall) : 0;\n\n// Pass if F1 >= 0.7 (allows some flexibility for multi-agent scenarios)\nconst pass = f1 >= 0.7;\n\nreturn {\n  pass: pass,\n  score: f1,\n  reason: `F1: ${f1.toFixed(2)}, Precision: ${precision.toFixed(2)}, Recall: ${recall.toFixed(2)} | Expected: [${expected.join(', ')}] | Got: [${suggested.join(', ')}]`\n};\n"
        },
        {
          "type": "javascript",
          "value": "const proactiveAgents = {\n  'datadog-specialist': ['datadog', 'observability', 'monitoring', 'metrics', 'telemetry', 'tracing', 'apm', 'opentelemetry', 'instrumentation'],\n  'research-analyst': ['how does', 'how do', 'best practices', 'documentation', 'look up', 'fetch docs', 'research', 'api reference'],\n  'test-automator': ['test', 'testing', 'qa', 'quality', 'coverage'],\n  'aws-cloud-specialist': ['aws', 'cloudformation', 'lambda', 's3', 'rds', 'iam'],\n  'eventsourcing-expert': ['event sourcing', 'aggregate', 'projection', 'domain event', 'cqrs', 'event store'],\n  'promptfoo-specialist': ['promptfoo', 'llm testing', 'prompt evaluation', 'red team'],\n  'toolkit-manager': ['agent', 'skill', 'toolkit']\n};\n\nconst request = (context.vars.user_request || '').toLowerCase();\nconst trimmed = output.trim();\nconst suggested = trimmed === 'NONE' ? [] : trimmed.split(',').map(a => a.trim());\n\nlet violations = [];\nfor (const [agent, triggers] of Object.entries(proactiveAgents)) {\n  const hasTriggered = triggers.some(t => request.includes(t));\n  const wasSuggested = suggested.includes(agent);\n\n  if (hasTriggered && !wasSuggested) {\n    violations.push(`PROACTIVE agent ${agent} should trigger but was not suggested`);\n  }\n}\n\nif (violations.length > 0) {\n  return {\n    pass: false,\n    score: 0,\n    reason: violations.join('; ')\n  };\n}\n\nreturn { pass: true, score: 1, reason: 'PROACTIVE agents correctly handled' };\n"
        }
      ],
      "vars": {},
      "options": {},
      "metadata": {}
    },
    "outputPath": [
      "results/baseline.json"
    ],
    "extensions": [],
    "metadata": {},
    "evaluateOptions": {
      "maxConcurrency": 10,
      "cache": true,
      "showProgressBar": true
    }
  },
  "shareableUrl": null,
  "metadata": {
    "promptfooVersion": "0.119.9",
    "nodeVersion": "v25.1.0",
    "platform": "darwin",
    "arch": "x64",
    "exportedAt": "2025-11-21T11:02:11.315Z",
    "evaluationCreatedAt": "2025-11-21T11:02:07.678Z"
  }
}